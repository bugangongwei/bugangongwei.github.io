---
title: 面试题
date: 2021-08-16 14:10:00
tags: [interview]
categories: interview
comments: true
---


# 业务


# 数据库
### 对 SQL 的优化方式
1. 子查询: 如果查询的两个表大小相当，那么用 in 和 exists 差别不大；如果两个表中一个较小一个较大，则子查询表大的用 exists，子查询表小的用 in;
````sql
-- 例如：表A(小表)，表B(大表)
-- A 表使用 cc 索引, B 表全面扫描, 不划算
select * from A where cc in (select cc from B);
-- A 全表扫描, B 使用 cc 索引, 划算
select * from A where exist(select cc from B where cc=A.cc);

-- 相反的
-- A 全表扫描, B 使用 cc 索引, 划算
select * from B where cc in (select cc from A);
-- A 全表扫描, B 使用 cc 索引, 划算
select * from B where exist(select cc from A where cc=B.cc);
````

2. 子查询: 无论哪个表大，用 not exists 都比 not in 要快
````sql
-- 内外都要全表扫描
select * from t1 where c2 not in (select c2 from t2);
-- 内查询可以使用 c2 索引
select * from t1 where not exists (select c2 from t2 where c2=t1.c2);
````
bug: 如果子查询返回的值中有任意一条记录含有 null 值, 则整个查询不返回任何记录, 这个规则极易引起失误; 所以我们尽量不使用 not in;

3. 避免在索引列上使用 is null 和 is not null
注意⚠️事项: 单个索引不存储 null 值, 组合索引不存储全为 null 的值, 原因是索引应该是有序的, 但是 null 是破坏有序性的, 所以干脆不存;
替代方案: 
a. 把 NULL 转换成特定值, 使用特定值查找, a is not null 改为 a>0 等...
b. 建立复合索引;
效率分析:

````sql
create table student
(
    id int primary key not null ,
    sid   int
);
CREATE INDEX STU_SID ON STUDENT( SID    ASC);

-- 两种选择
-- (1) 索引扫描全部非 null 数据, 根据索引扫描扫描主键, 遇到索引扫描中的 id 就跳过
-- (2) 全表整块读取, 找出 is null 的数据
-- (1) 更快, 优化器会选择(1), 扫描索引 STU_SID, 找到所有非 null 的节点的 id (索引不保留 null 值)
-- 全表扫描, 一旦遇到上面这些数据, 不读取数据, 否则, 读取数据
select * from student where sid is null;

-- 两种选择
-- (1) 索引扫描全部非 null 数据, 根据索引扫描读取全部数据
-- (2) 全表扫描, 整块读取全部数据
-- (2) 更快, 优化器会选择(2), 因为(1)扫描完索引之后, 需要去主键一个一个读取数据; 而(2)全表扫描会一次读取一整个 block, 所以效率更高;
select * from student where sid is not null;
````

4. 考虑在 where 和 order by 后面的列建立索引
5. 如果数据是连续的, 能用 between 就不用 in
6. or 查询如果是相同字段, 可以用 in 替代

### 索引失效的情况
(1) 重复值太多的列 (如: TYPE 有 5 个值, 查找 TYPE = 1 时, 索引失效)
(2) 前导模糊查询 ("%XX", "%XX%"...)
(3) 函数导致的索引失效 (DATE())
(4) 类型不一致导致的索引失效 (其实类型转换是函数调用, 函数调用会使索引失效)
(5) 表达式导致的索引失效 (... where age-1=18)
(6) or 引起的索引失效 (or )
(7) not in, not exist 导致索引失效
(8) is null, is not null 导致索引失效
(9) 复合索引, 最左匹配原则
(10) 复合索引, 如果使用了 != 或 <> 会导致后面的索引全部失效

### mysql explain
1. id, id 越大, 查询优先级越高
2. select_type
(1) SIMPLE: 简单查询, 不包括子查询和 UNION 查询
(2) PRIMARY + SUBQUERY: 外部查询和子查询, 一般是一起的
(3) PRIMARY + DERIVED: 在from列表中包含的子查询会被标记为DERIVED(衍生)，MySQL会递归执行这些子查询，将结果放在临时表中。
(4) UNION: 若第二个select出现在union后，则被标记为UNION，若union包含在from子句的子查询中，外层select将被标记为DERIVED。
(5) UNION RESULT: 从union表获取结果的select。
3. sql 语句操作的表
4. partitions: 表所在的分区
5. type: 性能 system>const>eq_ref>ref>range>index>ALL 表示查询所使用的访问类型
(1) system: 表只有一行记录（等于系统表），是const的特例类型;
(2) const: 表示通过一次索引就找到了结果，常出现于 primary key 或 unique 索引, 如 ... where id = x ;
(3) eq_ref: 唯一索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见主键或唯一索引扫描。
(4) ref: 非唯一性索引扫描，返回匹配某个单独值的所有行。本质上也是一种索引访问，返回匹配某值（某条件）的多行值，属于查找和扫描的混合体。
(5) range: 只检索给定范围的行，使用一个索引来检索行，可以在key列中查看使用的索引，一般出现在where语句的条件中，如使用between、>、<、in等查询。
(6) index: 全索引扫描，index和ALL的区别：index只遍历索引树，通常比ALL快，因为索引文件通常比数据文件小。虽说index和ALL都是全表扫描，但是index是从索引中读取，ALL是从磁盘中读取。
(7) ALL: 全表扫描
6. possible_keys: 显示可能应用在表中的索引，可能一个或多个
7. key: 实际中使用的索引，如为NULL，则表示未使用索引。若查询中使用了覆盖索引，则该索引和查询的select字段重叠。
8. key_len: 表示索引中所使用的字节数，可通过该列计算查询中使用的索引长度。在不损失精确性的情况下，长度越短越好。key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，并不是通过表内检索出的。
9. rows: 根据表统计信息及索引选用情况大致估算出找到所需记录所要读取的行数。当然该值越小越好
10. filtered: 百分比值，表示存储引擎返回的数据经过滤后，剩下多少满足查询条件记录数量的比例
11. Extra: 额外信息
(1) Using filesort: 表明mysql会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取; 归并排序+快排
(2) Using temporary: 使用了临时表保存中间结果，常见于排序order by和分组查询group by
(3) Using index: 表明相应的select操作中使用了覆盖索引，避免访问表的额外数据行，效率不错。
如果同时出现了 Using where，表明索引被用来执行索引键值的查找
如果没有同时出现 Using where，表明索引用来读取数据而非执行查找动作

### B- 树和 B+ 树的区别
B- 树: 每个节点都存储数据
B+ 树: 只有叶子节点存储数据, 叶子节点间有相邻指针

### 为什么 mongodb 使用 B- 树而 mysql 使用 B+ 树呢?
1. mysql 结构型数据库
结构型数据库的设计遵循三范式, 即“尽可能地减少冗余”, 这就导致在设计实体关系模型时, mysql 通常会把数据拆分成多个表, 在需要查询更多信息时, 难免要进行关联查询;
而关联查询则需要把一个表的一组结构放到另一个表进行查询, 一般都要遍历的;

例如学生表 t_student(sid, sname, cid), 班级表 t_class(cid, cname)
````sql
SELECT * FROM t_student t1, (
    SELECT cid
    FROM t_class
    WHERE cname = '1班'
  ) t2
WHERE t1.cid = t2.cid
```` 
比如这个语句就难免要在 t_student 表中遍历 cid = 1 的情况(通过索引找到 cid = 1, 也要继续向右遍历知道找到第一个不等于 1 的 cid)

2. mongodb 聚合型数据库
mongo 也可以使用 lookup 进行类似 union 的联合查询, 但是一个好的非关系型数据库设计, 是反三范式的, 更好的情况是把数据都聚合在一起;

````json
{
  "class_1": {
    "_id": 1,
    "name": "class 1",
    "students": [
      {
        "_id": 1,
        "name": "a"
      },
      {
        "_id": 2,
        "name": "b"
      }
    ]
  },
  "class_2": {
    "_id": 2,
    "name": "class 2",
    "students": [
      {
        "_id": 3,
        "name": "c"
      }
    ]
  }
}
````
非关系型数据库的数据更聚合, 通常一次查询就查到足够丰富的信息, 范围查询的场景比较少;

3. 各自优势
mongodb 不注重范围查询, 但是注重等值查询, 所以使用 B- 树, 最好时间复杂度为 O(1), 最差为 O(logn), 平均查询复杂度比较好;
mysql 很注重范围查询, 所以使用 B+ 树, 稳定的时间复杂度为 O(lonn);

### 事务隔离级别
(1) 读未提交
(2) 读提交
(3) 可重复读
(5) 串行化, 顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行

### 脏读, 幻读
脏读: 当前事务读到了别的事务修改后未提交的数据;
幻读: 当前事务读到了别的事务插入的满足当前事务查询条件的数据;

### IO 多路复用
1. select
select的几大缺点：
（1）每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大
（2）同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大
（3）select支持的文件描述符数量太小了，默认是1024

2. poll
poll 基于 select 的改进是, 把 fd_set 换成 pollfd 结构, 从限定长度的数组换成不限制长度的链表, 解决了问题 (3), 即 poll 没有最大文件描述符数量的限制;

3. epoll
原理: 红黑树+双向链表+回调机制

描述:
当某一进程调用epoll_create方法时，Linux内核会创建一个eventpoll结构体;
通过epoll_ctl方法向epoll对象中添加进来的事件, 这些事件都会挂载在红黑树中，如此，重复添加的事件就可以通过红黑树而高效的识别出来(红黑树的插入时间效率是lgn，其中n为树的高度);
所有添加到epoll中的事件都会与设备(网卡)驱动程序建立回调关系，也就是说，当相应的事件发生时会调用这个回调方法;
这个回调方法在内核中叫ep_poll_callback,它会将发生的事件添加到rdlist双链表中;
当调用epoll_wait检查是否有事件发生时，只需要检查eventpoll对象中的rdlist双链表中是否有epitem元素即可。如果rdlist不为空，则把发生的事件复制到用户态，同时将事件数量返回给用户

使用:
第一步：epoll_create()系统调用。此调用返回一个句柄，之后所有的使用都依靠这个句柄来标识。
第二步：epoll_ctl()系统调用。通过此调用向epoll对象中添加、删除、修改感兴趣的事件，返回0标识成功，返回-1表示失败。
第三部：epoll_wait()系统调用。通过此调用收集收集在epoll监控中已经发生的事件。


### mvcc
#### 快照读/可重复读
InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务 ID。“活跃”指的就是，启动了但还没提交;
数组里面事务 ID 的最小值记为低水位，当前系统里面已经创建过的事务 ID 的最大值加 1 记为高水位。这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）;

undo log 只针对 UPDATE 和 DELETE
可重复读的时候, 去查找当前事务维护的 undo log, 找到低水位以下的数据;

#### update
当前读
写 undo log

### 主键
自增 id 的优点
(1) 大小来看, 主键长度越小, 主键索引节点占据空间越小, 普通索引叶子节点占据空间越小;
(2) 自增, 插入过程中 ID 是有序插入, 那么, 可以不用考虑页分裂问题, 提升性能;


### redis 五种数据结构和底层数据结构
1. string: set/get/incr/decr/incrby/decrby
2. hash: hset/hget/hmget
3. list: 先入先出, lpush/lpop/rpush/rpop/llen
4. set: 无重复元素, sadd/scard(元素个数)/sismember(元素是否存在)/srem(删除某个元素)
5. zset: sorted set, zadd/zcard/zrange


|| 组件 || 分片算法 || 重分片 || 复制集 || Leader 选举机制 || 索引方式 || 事务 ||
| Redis 
| 槽指派, 16384个槽全部指派完成集群才上线 
| online行为, 添加和删除时, 指定槽转移到别的节点上去 
| 复制集
2.8 以前, 只有 SYNC;
2.8 以后, PSYNC 1, PSYNC + 复制积压缓冲区 + server ID;
4.0 之后, PYSNC 2, PSYNC + 复制积压缓冲区 + replid1 + replid2, replid1 保存当前复制的 master 的 replid, 而 replid2 只在 slave 上升到 master 时才使用, 保存自己的 server id 
| Sentinel 选举 Leader, Raft 协议(http://thesecretlivesofdata.com/raft/); 从服务器选举 master, 从可靠的从服务器列表中, 按照优先级+偏移量+serverId的排序选择新的 master 
| 没有索引 
| 原子性: 命令在一个队列中, 要么都执行, 要么都不执行;
一致性: 命令入队期间检查语句, 命令执行期间仅返回错误, 没有回滚;
隔离性: 单线程, 隔离性完全满足;
持久性: 取决于 Redis 的持久化机制;
| Mysql 
| 分库分表 
| 重新分库分表
| master-slave
binlog + 三个线程(dump_thread, I/O thread, sql_thread) 
| change master + 位点 或者 GTID(serverID + transactionID) 
| B+ 树 
| 原子性: 通过 undo log 实现事务回滚;
一致性: 类型检查等;
隔离性: 锁机制+MVCC(RR隔离级别下);
持久化: Redo log, bin log, 两阶段提交
| MomgoDB 
| Range/Hash/Zone/分片键
| MongoDB 分片是分成一个个默认 64M 大小的 chunk, 然后 chunk 大于指定大小时, 组件 balancer 会对 chunk 转移 
| 副本集
local.oplog.rs(容量到达上线会删除旧数据, oplog 的幂等性)
| 和 Redis 差不多, 筛选可用的 Secondry + 优先级 + 最新 oplog 
| B 树 
| 
| ElasticSearch
| 按照文档 ID 进行 hash 
| 重新计算分片
| Bully 算法, 发现 leader 宕机后即告诉编号比自己大的节点, 让他们去选举编号最大的节点作为新的 leader
| 倒排索引
| - |






# 介绍自己的项目
## 定时加载内容
(1) 同步加载
获取表数据最近修改时间
show table status like table_name;
select update_time from information_schama where TABLE_SCHEMA = table_name;
判断是否版本更新, 如果更新, update 数据;
更新本地版本号

(2) 定时加载
select + ticker
select 的优先级:
select 只要有一个 case 能够满足, 就立即执行;
select 同时有多个 case 能满足, 则随机选择一个 case 执行;
当所有 case 都不能满足时, 如果有 default 就执行 default, 否则阻塞监听;

## 分库分表
(1) 设计分库分表数
根据目前的表行数, 表 size, 表月增长量, 以及 DBA 给出的最佳实践(table_nums<1w, rows<500w, table_size<20G), 设计分库数量和分表数量;
设计分表规则: 查询按照 user_id 和 course_id 来, 那么, 使用 user_id 作为分表规则的 key, 做 hash 运算;
创建新库和空表;

为什么不用一致性 hash?
因为表和库的设计已经预留了十年的增长, 不太会有表的个数增减的场景, 普通的 hash 就可以满足;

(2) 历史数据同步脚本
设置一个截止 id, 叫做 idx, 设置 step 为一个 worker 处理的 rows 个数, 以及一个 worker_num;
开始多个唯一 worker, 按照 step 划分 id 范围, 根据范围读取源数据, 并写入新表;

(3) 增量数据同步脚本
开始消费 CDC 数据, 设置 initialOffset 为 Oldest, 因为在历史数据同步开启之后, 还是有一些 CDC 数据产生, 需要处理这些数据变更;
消费到插入数据类型, 判断 id 是否大于历史数据同步时设置的戒指 id, 如果不大于, 就不插入, 否则会报 Duplicated Entry 的错误;
消费到更新数据类型, 直接更新, 就算更新 rows 为 0 也不报错, 因为 CDC 开启时间比历史数据同步早, 会有已经更新的数据在新的库里;
表设计是软删, 所以没有删除数据类型的考虑; (因为用户数据还需要保留, 用户重新添加课程后可以看到之前学习的记录)

(4) 同步基本完成后, 业务切换到新库新表, 直到 CDC 完全没有内容后, 可以停掉 CDC

## 搜索服务
Mysql 设置 bin_log 式的 CDC: log_bin=ON, binlog_format=ROW, binlog_row_image=FULL
读取 binlog 并生产 kafka 消息: Debezium, 一个监控数据变化的组件, 基于 kafka, 可支持 SQL, MongoDB, Oracle 等组件;
kafka 配置: CDC 需要保证顺序, 所以 kafka 只有一个 partition;
消费者: 对该 topic 只开启一个 consumer, 保证顺序消费, 因为 kafka 的消费是按照 pull 的方式来的, 所以消费速率由消费者决定;

ElasticSearch 面试点:
(1) 简要介绍一下 ES
ElasticSearch 是一款基于 lucene 的开源搜索引擎, 通过把强大但是不太好使用的 lucene 进行包装, 暴露出易于操作的 RESTful 风格的 API, 让这款搜索引擎更容易被开发者使用;
ES 通常用在垂直搜索领域中, 提供领域数据的模糊搜索功能; 分别有几个关键的概念 index, document, field, mapping, DSL 和 SQL, 代表的数据的组织和架构形式; ES 和 redis 一样提供了支持海量数据和高可用的分片式集群和复制集功能, 通过计算 document_id 的 hash 值来映射不同的分片, 通过 snapshot API 进行数据备份;

## 口语课接 CMCC
.course 文件通过 git 提交到仓库, 然后通过 CI 跑脚本, upload 到 OSS, 然后后端服务从 OSS 加载课程提供给客户端使用;
在 upload 之前, 因为是 .course 的文件, 是自然人理解的文件类型, 需要按照设定的规则进行语法和词法的分析, 将 .course 文件, 构造成一棵 Node Tree;
通过对不同的课程定义不同的 PB 结构, 在解析程序中, 对每种课程类型, 都定义自己的 Encode 和 Decode 函数, 可以将 Node Tree 序列化为 PB 数据, 通过 GRPC 提供给其他端;

## golang GC 重要版本迭代
(1) v1.5 之前, 标记清除法, 扫描和清除阶段全都要 STW;
(2) v1.5 三色标记法 + 插入写屏障技术
- 三色标记法:
标记清除算法, 新建对象, 如果是在非 GC 扫描时, 应该置为 0, 在 GC 期间为了防止被误删, 需要设置为 1; 没有这个判断, 所以新建对象状态都为 0, 在 GC 阶段, 为了防止误删, 使用 STW 来保护对象;
而三色标记法, 遍历灰色对象队列, 直到结束, 给了一个中间态, 使所有新建对象都能被扫描到, 从而允许异步进行 GC;
- 插入写屏障
上面说到, 所有新建对象为了被扫描到都需要标记为灰色, 插入写屏障正是给新建对象函数插入一个标记对象颜色的代码, 使得新建对象变成灰色, 确定能够被扫描到;
- 问题
每个 Goroutine 中有栈空间, 成千上万的栈空间内有成千上万个栈对象, 所以, 每个对象都需要插入写屏障, 那么会增加写入指针的额外开销;
所以 Go 团队不在栈对象上加入插入写屏障, 而是在扫描时直接置为灰色, 这时候栈扫描就需要 STW 来保护对象;
(3) v1.8 混合写屏障
 - 栈对象扫描并全部置为黑色
 - 栈对象新建也置为黑色(插入写屏障)
 - 删除写屏障(老对象删除引用并置为灰色, 新对象置为灰色(插入写屏障))

## Golang GC 过程
(1) 暂停准备阶段, STW, 使用基于信号的抢占式调度, 通过信号直接中断所有协程;
(2) 状态切换至 `_GCmark`, 开启写屏障, 用户程序协助(Mutator Assiste), 跟对象入队列;
(3) 结束 STW;
(5) 异步标记
(6) 标记终止阶段, STW;
(7) 状态切换 `_GCmarktermination` , 关闭 Mutator Assiste, 初始化清除状态, 关闭写屏障;
(8) 结束 STW;
(9) 并发清除;

## RPC 明明已经设置 timeout 了, 但 p99 还是很高?
### timeout 设置不合理
(1) 只设置了单次 socket timeout, 没有设置 circuit breaker
### GC 问题
(1.7 遇到的问题, 1.15 不一定还存在)
Golang 没有使用 Java 那样的分代机制, 导致每次 GC 时, 常驻内存对象也会进行扫描, 如果常驻内存对象太大了, GC 压力就过大, 此时就需要用户态 goroutine 来协助标记对象, 此时会影响程序的运行时间;

## 锁
### 互斥锁和自旋锁
同: 已经有一个线程加锁成功之后, 其他线程都会加锁失败; 都通过 CAS 来加锁
异: 互斥锁机锁失败以后会释放 CPU, 自旋锁加锁失败以后会忙等待, 不释放 CPU

互斥锁和自旋锁, 如何选择?
互斥锁开销大, 线程上下文切换[几十纳秒到几毫秒间]
- 第一次上下文切换: 线程加锁失败之后, 切换到内核态, 内核会把线程从[运行]状态设置为[睡眠]状态, 把 CPU 调度给其他线程;
- 第二次上下文切换: 锁被释放后, 内核可能会把[睡眠]的线程唤醒, 进入[就绪状态], 如果抢到锁, 那么就把 CPU 给他;
自旋锁不释放 CPU, 加锁解锁都通过用户态的 CAS 来执行, 没有上下文切换, 一定要配合抢占式调度使用, 不然可能一直不释放 CPU

当代码执行时间长, 可以用互斥锁, 代码执行时间短, 可以用自旋锁;

### 读写锁
- 读优先锁: 写锁加锁时遇到读锁, 阻塞, 写锁容易饿死
- 写优先锁: 读锁加锁时遇到写锁, 阻塞, 读锁容易饿死
- 公平读写锁: 公平入队, 先到先加锁

### 乐观锁, 悲观锁
悲观锁: 互斥锁, 自旋锁, 读写锁
乐观锁: 先修改共享资源, 再验证这段时间内有没有冲突, 如果有冲突, 就放弃本次操作, 然后再重试, 如在线文档编辑, Git, Svn 等...;

- 数据库的乐观锁和悲观锁
乐观锁: 为数据表添加一行 version/时间戳 字段, 更新的时候, 通过对比当前 version 和查询操作获取的 version 是否相同来确定是否更新;
悲观锁: 行锁的悲观锁包括共享锁(lock in share mode) 和排它锁(for update)

## Golang 锁
### 同步原语
sync.Mutex{}, 互斥锁
sync.RWMutex{}, 读写锁
sync.WaitGroup{}, 阻塞等待
sync.Once{}, 代码只执行一次
sync.Cond{}, 满足条件再执行, BroadCast
### 扩展原语
sync.WaitGroup{} -> ErrGroup{}, 只要有一个报错, 就可以被捕捉到;
Semaphore: 信号量
SingleFlight: 减少瞬时流量


# BT once
## 口语课
### 为什么使用内存缓存课程?
背景: 在一些需要批量获取课程信息的复杂接口中, 课程信息获取接口的调用需要更快的响应速度, 以免成为 to-C 接口的瓶颈;

课程内容在 Mysql 中数据量不大, 批量查询也没有慢查询, 在 mysql 中进行优化的空间很小;

因为课程详细信息都在一个字段中且使用 json 模式编码, 所以每次获取课程信息都需要 unmarshal 课程内容, 课程内容字段比较多, 有些还需要对翻译进行选择, 这是拖慢速度的原因之一;

基于以上的猜想, 决定使用缓存进行访问加速;

缓存方式无非是本地缓存和分布式缓存, 分布式缓存可以考虑在我们公司可提供的组件里面, 一般考虑 redis 和 codis, 这两种底层的数据结构都是字符串类型, 仅仅提高了数据获取的速度, 但是没有缓解 unmarshal 的问题, 并不是我们想要的结果;
本地缓存虽然没有分布式缓存那么强大, 但考虑到课程内容是教研录入的, 对内容修改的一致性和实时性的要求没那么高, 以及数据量不大, 微服务的 pod 数不是很高, 所以选择本地缓存也不会浪费太多内存, 所以选择了简单的本地缓存来缓解这个问题;


### 如果是对实时性和一致性要求比较高的场景, 会怎么做?
使用 redis 做分布式缓存, 保证不同的 pod 获取的都是同一份缓存数据, 当数据需要更新的时候, 把缓存删掉, 保证数据的实时性;
如果数据量比较大, 可以考虑使用 codis 提高吞吐量;

### 最后提高了多少?
改造的实际过程改造了三点: 微服务少一层 grpc 调用, 加入缓存(磁盘->内存), 去除 unmarshal 过程, 所以最终接口快了很多, 总之变绿了;

### 为什么使用缓存自动更新组件?
背景: 提高访问速度, 
为什么不用本地缓存? 不符合数据量小, 数据量可控的特点, 也没有一定要对象保存的需求, 反而可能浪费内存;
为什么使用 redis ? 在业务发展初期, 暂时没有集群的场景;
为什么要自动更新缓存? 缓存自动更新组件的源数据支持 grpc 数据, mysql 数据等, 除了本地数据更新能及时通知到缓存, 其他服务的数据更新不可能都通过消息服务来通知到, 因为这对第三方来说要增加工作量, 所以我们的缓存更新不应该是数据源触发; 
那缓存设置过期时间, 不就可以自动触发缓存更新了么? 每次请求都判断一下是否过期, 没过期则取出, 已经过期则回源;
可以, 但是如果能够自动回源的话, 那请求的响应速度就完全和源数据解耦了, 速度稳定, 并且源数据的抖动完全不影响用户体验;

注意点:
(1) 设置过期时间, 访问稀疏的数据, 可以及时过期掉以免占用内存, 访问频繁的数据在每次更新之后都更新过期时间, 基本可以做到热 key 不过期的问题, 避免单 key 流量太大在 key 过期那瞬间对 DB 或接口造成太大压力(缓存击穿?)
(2) 分布式锁, 更新间隔时间, 避免频繁的回源;
(3) 只缓存实时性要求不那么高的数据, 对实时性要求太高的数据, 可以不使用缓存, 比如接口返回中包含人数统计, 那这个数据就不接缓存; 如果接口并发量很大, 那么避免下游接口崩溃呢? 可以考虑使用并发控制和降级策略, 比如令牌桶算法, 计数器算法等, 避免太多的流量打爆下游服务, 以及通过兜底策略, 让报错的接口能够返回兜底数据; 如果该接口是重要接口, 需要保证高并发量下的准确性, 那么在设计之初, 需要考虑到下游的承载能力, 考虑是否需要在下游做缓存, 多几缓存, 集群等手段来增加下游的吞吐量; 如果某个接口包括既要调用实时性不高的外部接口又要调用实时性很高的外部接口, 那么, 可以自由考虑是否需要使用缓存, 那缓存组件的设计就需要更灵活, 可以使用设计模式来实现, 比如插件模式;

### 为什么要重构搜索服务?
因为 java 不是我们公司的主流语言, 基本没有人愿意去读, 遇到问题不能很快去定位;
Infra 的很多大改造这些老服务可能都是最后啃的, 大家都没有经验;
正好别的服务也要接 ES, 其实逻辑是差不多的, 借着这个机会改造一些, 后面接任何接 ES 的服务都比较方便;


### 精细化运营服务
什么是精细化的运营服务?
包括精细化到人群的广告投放, 定时活动投放, ab 实验, 弹窗等一系列运营活动的灵活投放;
如何精细化到人群?
用户需要有标签, 数据部门会提供用户的标签, 我们需要根据用户信息判断用户属于哪个标签;




















