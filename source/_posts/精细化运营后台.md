---
title: 精细化运营系统
date: 2021-10-11 00:00:00
tags: [架构设计]
categories: 架构设计
comments: true
---

精细化运营系统能够根据用户特性, 节日, 地域等不同的场景灵活配置投放策略的资源投放平台, 主要包含[精细化推荐 SDK], [投放系统], [资源管理系统], [DMP数据管理平台]这几个模块;

# 用户画像
用户画像是根据用户特征, 业务场景和用户行为等信息, 构建一个标签化的用户模型; 标签是用户画像的核心;
标签: 用户特征(性别, 年龄段, 是否会员, 消费能力...) 和用户行为(是否购买过课程, 购买过什么课程...)
人群: 标签的交集, 并集等复杂组合(如性别, 会员构成的并集女性会员)

## 需要考虑的问题
通过现有标签快速圈定人群(快速求标签的交集和并集)
持久化人群和用户关系
快速判断一个用户是否属于某个人群

## 用户标签体统的参考资料
产品类:
一篇文章带你从0到1掌握用户画像知识体系 https://www.linkflowtech.com/5631.html
40亿移动设备的用户画像和标签架构实践 https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&mid=2247486383&idx=1&sn=2e827743d1025dc7e458d7bd0d8bfd48&chksm=fbe9b260cc9e3b764a0041ed9260636c7b9206909558463d39b4f9ea8c050b9f8de07ce01572&scene=27#wechat_redirect
社交网络分析：微博得到最终用户标签的十一种假设 https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&mid=206881891&idx=1&sn=36614211645808e9c87b9f83ba335d8f&chksm=2fe93c30189eb526d2a5626415794a5bf70b473da3205b568f3a588c9355bf008f07d660ce36&scene=27#wechat_redirect
今日头条技术架构分析 https://mp.weixin.qq.com/s?__biz=MzUzMTA2NTU2Ng==&mid=2247518029&idx=4&sn=93050e5116d2cb2aa215ce5d866500d9&chksm=fa4af8fccd3d71eae9160580de559edded0615c42c6c0d00e54cd37d9ae8fb833de39f6c7478&scene=27#wechat_redirect

技术类:
使用Bitmap来存储海量用户标签系统 https://leriou.github.io/2017-12-29-user-tag-sys-on-bitmap/
「用户标签」在数据库设计时应该如何存储？https://www.cnblogs.com/yeahwell/p/11676480.html
万亿user_tags级实时推荐系统数据库设计 http://bigdataway.net/node/1009
实时用户标签生成系统设计 https://www.jianshu.com/p/969a2a30f64b
HBase与AI/用户画像/推荐系统的结合：CloudTable标签索引特性介绍 https://bbs.huaweicloud.com/blogs/163489
案例分析：如何搭建用户标签系统： https://www.cnwebe.com/articles/47422.html
DMP平台在贝壳的实践和应用 https://mp.weixin.qq.com/s?__biz=MzIyMTg0OTExOQ==&mid=2247485738&idx=1&sn=71d61dae19c6d6111e25e420207600f9&chksm=e8373a5adf40b34c072a79d6e05d2e1d87c7b78adfcabd30f8b0df09b3ccab79db13d2c4733c&scene=21#wechat_redirect
bitmap用户分群方法在贝壳DMP的实践和应用 https://mp.weixin.qq.com/s/VijSTxDj65cAl2XmbWHiJA
实时推荐系统: http://bos.itdks.com/11f2fbf3c59f4435a92429361c3f4f5e.pdf
苏宁超6亿会员如何做到秒级用户画像查询？ https://www.modb.pro/db/40263
有赞DMP平台实践 https://tech.youzan.com/dmp-in-youzan/
设计大型 DMP 系统（上）：MongoDB 并不是什么灵丹妙药 https://moore.live/news/176072/detail/
数据中台：基于标签体系的360°用户画像 https://jishuin.proginn.com/p/763bfbd283ab
用户标签体系建设的四字箴言 https://www.dtstack.com/1794/

基础技术:
clickhouse: https://aws.amazon.com/cn/blogs/china/explore-three-ways-to-combine-clickhouse-and-amazon-s3/
Apache Druid
http://www.apache-druid.cn/GettingStarted/chapter-1.html
https://juejin.cn/post/6844904083506069517
https://yuzhouwan.com/posts/5845/
Amazon Redshift
https://docs.aws.amazon.com/zh_cn/redshift/latest/dg/tutorials-redshift.html
八大最佳实践 https://www.infoq.cn/article/bg5jivowfgi5pzog9nqp
数据仓库解决方案 - RedShift 入坑指南 https://zhuanlan.zhihu.com/p/29184898
从 Redshift 迁移到 ClickHouse 后再无数据丢失 https://www.infoq.cn/article/f3si3u-8sh6l3ldgxudk
在生产中结合使用 Amazon Redshift Spectrum、Amazon Athena 和 AWS Glue https://www.infoq.cn/article/DrZS5S3br016F0lSwdaj?utm_source=related_read_bottom&utm_medium=article
Hbase: https://wiki.liulishuo.work/display/ops/Hbase
hbase基本概念 https://wiki.liulishuo.work/pages/viewpage.action?pageId=121493489
Kv for Hbase https://wiki.liulishuo.work/display/ops/Kv+for+Hbase

## 存储方案选型
### Aerospike
参考设计方案: https://moore.live/news/176072/detail/
AeroSpike 是基于内存和SSD固态硬盘的高速KV数据库, 在查询速率, 高可用, 高并发和海量数据等方面的表现都不错, 不过这里的方案中没有考虑到圈人群的问题, 如果要进行标签组合的话, 可能还需要自己实现交并集运算;

AeroSpike vs Redis: 
https://brands.cnblogs.com/aerospike/p/1870
https://brands.cnblogs.com/aerospike/p/1871
https://brands.cnblogs.com/aerospike/p/1868

### Redis
参考方案设计: https://leriou.github.io/2017-12-29-user-tag-sys-on-bitmap/
Redis 支持二进制位数组, https://weread.qq.com/web/reader/d35323e0597db0d35bd957bk82a32a302a282aa4b0af8ce
使用 Redis Bit 存储标签, 利用 bitop and 和 bitop or 操作能够快速进行并集和交集运算, 用于圈定人群

如何查找 bitmap 中的所有 1 或者所有 0 ? 可以参照 redis bitcount 的实现方式, 查表/variable-precision SWAR 算法
如何解决稀疏 bitmap 问题? 采用分段的思想

lls设计思路
圈人结果中获取user_id,  将user_id存储到redis bitset中;由于redis bitset最多直接存储512M(最大值为2^32)，并且存储空间会按最大offset计算，这样导致空间浪费极大;采用切片bitset的方案，将uint64类型数值存储到4个bitset中. 这样空间浪费和存储复杂度能达到一个我们能接收的均衡状态
````
Group{
 key_16 // 存储范围[0,2^16)
 key_32 // 存储范围[2^16,2^32)
 key_48 // 存储范围[2^32,2^48)
 key_64 // 存储范围[2^48,2^64)
}
````

### ClickHouse
参考设计方案: https://mp.weixin.qq.com/s/VijSTxDj65cAl2XmbWHiJA
参考设计方案: https://www.modb.pro/db/40263
这个方案给了详细的标签 Bitmap 设计, 包括枚举类型, 和连续值类型如何去设计 Bitmap 存储, 写的很不错;
ClickHouse 支持bitmapAnd, bitmapOr, bitmapXor, bitmapToArray, bitmapCardinality;
使用 spark 把 Hive 数据通过计算成 bitmap 存储到 ClickHouse 中;

### Hbase+Bitmap
参考方案设计博客: https://bbs.huaweicloud.com/blogs/163489
利用Hbase的”稀疏矩阵“特点, 以及数据实时更新, 数据强一致性的优势, 提供比 Apache Druid 更符合 OLTP 场景的服务;

标签通常与某类实体对象(Entity)有关, 每一个Entity所拥有的标签数量不等, 这属于典型的半结构数据场景, Hbase 的“稀疏矩阵”模型天然适合这类数据的存储;
但是Hbase受限的查询能力却极大地限制了基于灵活标签组合条件的数据搜索能力(Hbase不支持联合查询);

#### HBase天然适合标签数据存储
HBase的数据表，是一种"稀疏矩阵"的结构，没有严格的列结构定义，或者说，每一行都可以拥有自己的列定义。
举例说明如下：
````
Row1: {[Age:10_20], [City:Shenzhen]}

Row2: {[Age:20_30], [Occupation:Teacher]}

Row3: {[Age:30_40], [City:Guangzhou], [Occupation:Accountant]}
````
注: 假设Row1, Row2, Row3为RowKey，而"{""}"中的部分为这一行数据中所包含的所有列，每一个"[""]"中的内容一个列。可以看出来：不同的行所包含的列的集合可能不同。

如果将拥有标签数据的对象称之为一个实体，实体可理解成人、车辆、手机号码、图片等等，每一个实体所拥有的标签数量是不固定的，这天然与HBase数据表的"稀疏矩阵"特点吻合，再结合HBase自身的高性能随机读写能力、强数据一致性、优秀的线性扩展能力等特点，促成了很多标签应用选型HBase作为数据存储系统。

#### 仅有 Hbase 难以满足标签数据需求
关于标签数据，支持灵活的标签组合条件查询(ad-hoc查询)是一个普遍的需求，但基于原生HBase接口能力却难以达成此需求，最关键的原因在于HBase仅仅支持基于RowKey的快速查询能力，这意味着原生HBase所能提供的查询场景是有限的、确定的。如果要支持标签组合条件的ad-hoc查询，需要对HBase进行扩展，或者依赖于第三方技术来实现;

Hbase W3Cschool DOC: https://www.w3cschool.cn/hbase_doc/hbase_doc-vxnl2k1n.html
Hbase 官方文档: http://hbase.apache.org/book.html#_introduction 

### ElasticSearch
使用HBase来存储标签数据，而标签索引则基于Solr/Elasticsearch这样的"外挂"索引方案来实现，这是一种比较常见的组合应用方案，或者，直接将所有数据都存储在Solr/Elasticsearch中;

使用 ES 来存储标签, 无论是根据 user_id 查询标签还是根据标签来查询 user_ids 都很支持; 但是在标签聚合的问题上, 需要进行并集和交集的运算, ES 的运算能力无法支撑大规模数据的实时交并集运算;

#### ES 存储标签数据的几个典型问题
(1) 数据更新效率低, ES的Document被设计成Immutable的，因此，应用是无法直接更新一个Document的，除非进行完整的Document替换(标签数据是频繁更新的);
(2) 数据一致性弱，写入的数据无法立马可见, ES的近乎一秒实时性;
(3) 单Index/Collection支持数据量有限, 跨多天的查询很慢或无法计算出结;
(4) 读写并发场景下，高价值数据无法有效缓存: Segment需要时常合并，合并后原来的Cache失效，需要重新加载;
(5) Solr/Elasticsearch的分页查询也存在很大的性能问题，页数越大查询越慢;

# 资源投放中心

# 资源管理中心






